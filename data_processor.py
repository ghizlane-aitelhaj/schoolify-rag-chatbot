import os
from dotenv import load_dotenv
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS

# Loaders LangChain
from langchain_community.document_loaders import (
    PyMuPDFLoader,                      # PDF
    TextLoader,                         # TXT
    UnstructuredMarkdownLoader,         # .md
    UnstructuredWordDocumentLoader,     # .docx
    CSVLoader                           # .csv
)

# OCR pour les images
from PIL import Image
import pytesseract
from langchain.schema.document import Document  

# Chargement du .env
load_dotenv()

api_key_check = os.getenv("OPENAI_API_KEY")
if api_key_check:
    print(f"‚úÖ Cl√© API OpenAI trouv√©e : {api_key_check[:5]}*****")
else:
    print("‚ùå Cl√© API OpenAI non trouv√©e. V√©rifie ton fichier .env.")

# Dossier des documents
DOCS_DIR = "documents"
if not os.path.exists(DOCS_DIR):
    os.makedirs(DOCS_DIR)

def ocr_image_to_document(file_path: str) -> list:
    """Effectue l‚ÄôOCR sur une image et retourne une liste [Document]"""
    try:
        img = Image.open(file_path)
        text = pytesseract.image_to_string(img)
        if not text.strip():
            print(f"‚ùó Aucun texte d√©tect√© dans l'image : {file_path}")
            return []
        print(f"üßæ Texte extrait de l'image ({len(text)} caract√®res)")
        doc = Document(page_content=text, metadata={"source": file_path})
        return [doc]
    except Exception as e:
        print(f"‚ùå Erreur OCR sur l'image {file_path} : {e}")
        return []

def process_document(file_path: str):
    print(f"üìÑ Traitement du fichier : {file_path}")

    # S√©lection du bon loader selon l‚Äôextension
    try:
        if file_path.endswith(".pdf"):
            loader = PyMuPDFLoader(file_path)
            documents = loader.load()
        elif file_path.endswith(".txt"):
            loader = TextLoader(file_path)
            documents = loader.load()
        elif file_path.endswith(".md"):
            loader = UnstructuredMarkdownLoader(file_path)
            documents = loader.load()
        elif file_path.endswith(".docx"):
            loader = UnstructuredWordDocumentLoader(file_path)
            documents = loader.load()
        elif file_path.endswith(".csv"):
            loader = CSVLoader(file_path)
            documents = loader.load()
        elif file_path.endswith((".png", ".jpg", ".jpeg")):
            documents = ocr_image_to_document(file_path)
        else:
            print(f"‚ö†Ô∏è Format non support√© : {file_path}")
            return None

        if not documents:
            print("‚ùå Aucun contenu extrait.")
            return None

        print(f"üìö {len(documents)} document(s) charg√©(s)")

        # chunking
        splitter = RecursiveCharacterTextSplitter(
            chunk_size=1500,
            chunk_overlap=300
        )
        chunks = splitter.split_documents(documents)
        print(f"‚úÇÔ∏è {len(chunks)} chunks g√©n√©r√©s.")

        # Embedding
        embeddings = OpenAIEmbeddings()

        # FAISS
        if os.path.exists("faiss_index"):
            db = FAISS.load_local("faiss_index", embeddings, allow_dangerous_deserialization=True)
            db.add_documents(chunks)
            print("‚úÖ Ajout aux documents existants dans FAISS.")
        else:
            db = FAISS.from_documents(chunks, embeddings)
            print("‚úÖ Nouvelle base FAISS cr√©√©e.")

        db.save_local("faiss_index")
        print("üíæ Base FAISS sauvegard√©e.")
        return db

    except Exception as e:
        print(f"‚ùå Erreur lors du traitement : {e}")
        return None

def get_vector_store():
    embeddings = OpenAIEmbeddings()
    if os.path.exists("faiss_index"):
        print("üì¶ Chargement de la base FAISS existante...")
        return FAISS.load_local("faiss_index", embeddings, allow_dangerous_deserialization=True)
    print("‚ö†Ô∏è Aucune base FAISS trouv√©e.")
    return None

# bach ykoun exportable dans app.py
DOCS_DIR = DOCS_DIR
